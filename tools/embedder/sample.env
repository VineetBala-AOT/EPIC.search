# EPIC.search Embedder - Environment Variables Configuration
# 
# Copy this file to '.env' and update the values for your environment.
# These variables configure the connection to external services and 
# adjust the behavior of the document embedding system.

# API configuration
DOCUMENT_SEARCH_URL=https://example.com/api/public/search

# S3 Storage configuration
S3_BUCKET_NAME=your-bucket-name
S3_ACCESS_KEY_ID=your-access-key
S3_SECRET_ACCESS_KEY=your-secret-key
S3_REGION=your-region
S3_ENDPOINT_URI=https://your-s3-endpoint.com

# Database configuration
VECTOR_DB_URL=postgresql://user:password@hostname:port/database
AUTO_CREATE_PGVECTOR_EXTENSION=True     # Whether to auto-create the pgvector extension
RESET_DB=False                           # WARNING: If True, will DROP and recreate all tables on startup (dev/test only!)

# Database connection pool configuration (optional, auto-scaling defaults shown)
# Options for pool sizes: 'auto' (scales with FILES_CONCURRENCY_SIZE) or specific integer values
# DB_POOL_SIZE=auto                      # auto = 2x FILES_CONCURRENCY_SIZE (safe worker ratio)
# DB_MAX_OVERFLOW=auto                   # auto = 4x FILES_CONCURRENCY_SIZE (good overflow capacity)
# DB_POOL_RECYCLE=900                    # Seconds before recycling connections - 15 min (default: 900)
# DB_POOL_TIMEOUT=120                    # Seconds to wait for connection from pool - 2 min (default: 120)
# DB_CONNECT_TIMEOUT=60                  # Seconds to establish initial connection - 1 min (default: 60)

# AUTO mode examples:
# FILES_CONCURRENCY_SIZE=auto + DB_POOL_SIZE=auto → Intelligent scaling based on CPU cores
# FILES_CONCURRENCY_SIZE=8 + DB_POOL_SIZE=auto → Pool size = 16, overflow = 32

# High compute server settings for 8+ hour runs (prevents prepared statement buildup):
# DB_POOL_SIZE=24                        # Or use 'auto' with appropriate FILES_CONCURRENCY_SIZE
# DB_MAX_OVERFLOW=48                     # Or use 'auto'
# DB_POOL_RECYCLE=600                    # 10 minutes - shorter for stability on long runs
# DB_POOL_TIMEOUT=300                    # 5 minutes for patient connection waiting
# DB_CONNECT_TIMEOUT=120                 # 2 minutes for network delays

# Vector database table/index naming (optional, defaults shown)
EMBEDDING_DIMENSIONS=768                 # Dimensions of the embedding vectors

# Model settings - separate models for embedding and keyword extraction
# Both default to 'all-mpnet-base-v2' if not specified
EMBEDDING_MODEL_NAME=all-mpnet-base-v2
KEYWORD_MODEL_NAME=all-mpnet-base-v2

# Document chunking configuration (optional, defaults shown)
CHUNK_SIZE=1000                      # Size of text chunks in characters
CHUNK_OVERLAP=200                    # Number of characters to overlap between chunks

# Processing configuration with intelligent auto-configuration
# The embedder automatically optimizes settings based on your hardware
FILES_CONCURRENCY_SIZE=auto          # auto (recommended), auto-full, auto-conservative, or integer
KEYWORD_EXTRACTION_WORKERS=auto      # auto (recommended), auto-aggressive, auto-conservative, or integer  
CHUNK_INSERT_BATCH_SIZE=50           # Number of chunks per database batch (25 default, 50 for high-RAM systems)

# Keyword extraction performance modes - TEST DIFFERENT MODES FOR SPEED vs QUALITY
KEYWORD_EXTRACTION_MODE=fast         # standard, fast, simplified

# Performance mode options:
# KEYWORD_EXTRACTION_MODE=standard    → Full KeyBERT quality (baseline, slowest)
# KEYWORD_EXTRACTION_MODE=fast        → KeyBERT optimized + batch processing (2-4x faster, query-compatible)
# KEYWORD_EXTRACTION_MODE=simplified  → TF-IDF ultra-fast (10-50x faster, may affect search quality)

# Auto-configuration options:
# FILES_CONCURRENCY_SIZE=auto         → Half cores for 16+ CPU systems (prevents over-parallelization)
# FILES_CONCURRENCY_SIZE=auto-full    → All CPU cores (maximum parallelism)
# FILES_CONCURRENCY_SIZE=auto-conservative → Quarter CPU cores (resource-constrained)
# 
# KEYWORD_EXTRACTION_WORKERS=auto     → Optimized for KeyBERT bottleneck (2 threads for 16+ cores)
# KEYWORD_EXTRACTION_WORKERS=auto-aggressive → 4 threads per process (maximum keyword parallelism)
# KEYWORD_EXTRACTION_WORKERS=auto-conservative → 1 thread per process (minimal contention)
#
# Example results for 32-core server: auto = 16 processes × 2 threads = 32 total threads (100% CPU utilization)

# API pagination configuration (optional, defaults shown)
GET_PROJECT_PAGE=1                   # Number of projects to fetch per API call
GET_DOCS_PAGE=1000                   # Number of documents to fetch per API call

# OCR (Optical Character Recognition) configuration for scanned PDFs
OCR_ENABLED=true                     # Whether to process scanned PDFs with OCR (true/false)
OCR_PROVIDER=tesseract               # OCR provider: 'tesseract' (local) or 'azure' (cloud)

# Tesseract OCR settings (when OCR_PROVIDER=tesseract)
# TESSERACT_PATH=C:\Program Files\Tesseract-OCR\tesseract.exe  # Path to Tesseract executable (auto-detected if not set)
OCR_DPI=300                          # DPI for OCR image conversion (higher = better quality but slower)
OCR_LANGUAGE=eng                     # Language code for OCR (eng, fra, deu, etc.)

# Azure Document Intelligence OCR settings (when OCR_PROVIDER=azure)
# AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT=https://yourresource.cognitiveservices.azure.com/
# AZURE_DOCUMENT_INTELLIGENCE_KEY=your_api_key_here